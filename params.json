{"name":"AGILEPack","tagline":"Algorithms for Generalized Inference, Learning, and Extraction Package","body":"AGILEPack\r\n=========\r\n\r\nAlgorithms for Generalized Inference, Learning, and Extraction Package, By Luke de Oliveira.\r\n\r\n####Dependencies\r\n- [`Eigen`](http://eigen.tuxfamily.org/) matrix library (header only) for fast matrix operations.\r\n- Compiler support for C++11. If you're not sure and want to cross check your compiler version to see if it's ok, here's some support info about [GCC](http://gcc.gnu.org/projects/cxx0x.html) and [Clang](http://clang.llvm.org/cxx_status.html). Other compilers haven't been tested yet.\r\n- [`yaml-cpp`](https://code.google.com/p/yaml-cpp/ \"yaml-cpp Homepage\") for [`YAML`](http://www.yaml.org/ \"YAML Homepage\") parsing, but a version is made locally by default.\r\n\r\n####Summary\r\n\r\nThis is a work in progress, with the ultimate goal of a versatile Deep Learning library in C++. Support will be provided for interfacing with `*.root` files and providing complete training and testing specifications within the `YAML` specification and serialization file.\r\n\r\n\r\n####Installation\r\n\r\nThe package can be downloaded using\r\n```\r\ngit clone https://github.com/lukedeo/AGILEPack.git\r\n```\r\nand is relatively basic to install. As long as `Eigen` is in a place such that\r\n\r\n```c++ \r\n#include <Eigen/Dense>\r\n```\r\nwon't cause your compiler to yell at you, you should be able to build the whole shebang with\r\n\r\n```\r\nmake\r\n```\r\n\r\nThis will build a static library called `lib/libAGILEPack.a`, which you can then link against to do sweet things like build Deep Learners.\r\n\r\n####Basic Usage\r\n\r\nLet's say you have a program called `prog.cxx` that uses AGILEPack with ROOT stuff. Provided that your file takes the form\r\n```c++\r\n#include \"Base\"\r\n           ^~~~~~ Includes all AGILEPack stuff!\r\n#include <myotherheaders.h>\r\n\r\nint main(int argc, char const *argv[])\r\n{\r\n\t// Do stuff with AGILEPack!\r\n}\r\n```\r\n\r\nYou can compile this program with:\r\n\r\n```bash\r\ng++ -o prog prog.cxx `/path/to/AGILEPack/agile-config build --root`  \r\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\r\n      fixes include paths and links -lAGILEPack\r\n```\r\n\r\nwhich will produce an excecutable called `prog`.\r\n\r\nThe ordering of these arguments is **very important** on Linux (particularly on SLC)!\r\n\r\n\r\n####More compiling and linking stuff\r\n\r\nLet's say you're using AGILEPack as part of a larger project, and you need to produce a *.o and then then do other things. Stealing the example from the last section, let's say we want to produce `prog.o`. We can do this with\r\n\r\n```bash\r\ng++ -c `/path/to/AGILEPack/agile-config compile --root` prog.cxx -o prog.o\r\n```\r\n\r\nthen link it to other stuff with \r\n\r\n```bash\r\ng++ -o MyExcecutable prog.o [other *.o ...] `/path/to/AGILEPack/agile-config link --root`\r\n```\r\n\r\n\r\n\r\n\r\n####Algorithms and General Features\r\n\r\n- [x] Backpropagation for arbitrary layer structure.\r\n- [ ] Support for:\r\n  - [x] Linear layers with SSE loss.\r\n  - [x] Sigmoidal layers with SSE loss.\r\n  - [x] Softmax layers with Cross Entropy loss.\r\n  - [x] Rectified linear unit layers.\r\n  - [x] Autoencoder pre-training (stacked, denoising, etc.)\r\n  - [ ] Restricted Boltzmann Machine pre-training.\r\n  - [ ] Dropout/DropConnect layers.\r\n  - [ ] Inverted Deep Network Encoding. \r\n- [x] Dynamic changes to layers (additions, deletions).\r\n- [x] Interface with the CERN `ROOT` framework.\r\n- [x] Complete serialization of network structure with `YAML` file.\r\n- [ ] More to come...\r\n\r\n####I have qualms with AGILEPack\r\n\r\nIf there's something wrong with *anything* here, please bother me at `luke.deoliveira@yale.edu`.\r\n\r\n\r\n\r\n\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}